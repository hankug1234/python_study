# -*- coding: utf-8 -*-
"""kaggle_titanic

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D67jG0e-g75_Rhfn2rDv9zBdodQJKJPS

# 데이터 가져오기
"""

import pandas as pd
titanic = pd.read_csv("/content/train.csv")

"""#정보 보기 

"""

titanic.info()

"""# 비 수치형 데이터 확인 """

tot_index = pd.Series([dtype=='object' for dtype in titanic.dtypes])
ot_columns = titanic.columns[tot_index == True]
print(ot_columns)

"""# 결측 데이터 columns 확인"""

null_df = titanic.isnull().sum()
null_index = null_df.index[null_df != 0]
null_index

"""# 비 수치형 데이터 수치형 데이터로 변환

1.sex data

---


남자는 1 여자는 으로 변경(성병 구분만 진행 하면 데이터 손실 없이 변경 가능
할것이라 생각 하여 이렇게 진행)
"""

titanic["Sex"] = titanic["Sex"].map({"male":1,"female":0})

"""2.Name"""

family_name_set = set(titanic["Name"].map(lambda x: x.split(",")[0]))

first_class_index = titanic["Pclass"] == 1
first_class  = titanic[first_class_index]

second_class_index = titanic["Pclass"] == 2
second_class  = titanic[second_class_index]

third_class_index = titanic["Pclass"] == 3
third_class  = titanic[third_class_index]

def make_dict(l):
  dict ={}
  for fn in l:
    dict[fn] = []
  return dict

def fill_dict(dict,df):
  index = df.index
  for i in index:
    dict[df.loc[i,"Name"].split(",")[0]].append(i)
  return  dict

def classNames(df,l):
  return fill_dict(make_dict(l),df)

first_name_set = set(first_class["Name"].map(lambda x: x.split(",")[0]))
first_name_dict = classNames(first_class,list(first_name_set))


second_name_set = set(second_class["Name"].map(lambda x: x.split(",")[0]))
second_name_dict = classNames(second_class,list(second_name_set))

third_name_set = set(third_class["Name"].map(lambda x: x.split(",")[0]))
third_name_dict = classNames(third_class,list(third_name_set))

class_name_list = list(first_name_dict.values())
class_name_list.extend(list(second_name_dict.values()))
class_name_list.extend(list(third_name_dict.values()))
Name = list(range(0,titanic["Name"].size))
for i,num in enumerate(class_name_list):
  if i >= len(first_name_dict):
    i+=100
    if i >= len(first_name_dict)+len(second_name_dict):
      i+=100
  for index in num:
    Name[index] = i+1
titanic["Name"] = pd.Series(Name)

"""3.Cabin"""

titanic.drop(columns=["Cabin"],inplace=True)

"""4.Embark"""

import numpy as np
print(titanic['Embarked'].unique())
convert_dict = {"S":1,"C":2,"Q":3}
titanic["Embarked"] = titanic["Embarked"].map(lambda x:1 if x is np.nan else convert_dict[x])

"""5.Tikcet data"""

def ticket2int(ticket):
  return sum([ord(i) for i in ticket])

ticket_list = []
adder = titanic["Ticket"].map(ticket2int).mean()
for i in range(0,titanic["Ticket"].size):
  pclass = titanic.loc[i,"Pclass"]
  if pclass == 2:
    ticket = ticket2int(titanic["Ticket"][i])+adder
  elif pclass == 3:
    ticket = ticket2int(titanic["Ticket"][i])+adder*2
  else:
    ticket = ticket2int(titanic["Ticket"][i])
  ticket_list.append(ticket)  

titanic["Ticket"] = pd.Series(ticket_list)

"""# 결측치 보정

1.Age
"""

titanic.info()

from sklearn.tree import DecisionTreeRegressor

null_df = titanic.isnull().sum()
null_index = null_df.index[null_df != 0]
null_index

new_titanic = titanic.fillna(-1)
test_index = new_titanic.index[new_titanic["Age"] == -1]
print(len(test_index))
print(test_index)

predict = new_titanic.iloc[test_index,:]
predict_input = predict.drop(columns=["Age"])

train_index = new_titanic.index[new_titanic["Age"] != -1]
print(len(train_index))
print(train_index)

train =  new_titanic.iloc[train_index,:]

train_input = train.drop(columns=["Age"])
train_target = train["Age"]

train_target[:5]

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(train_input)
scaled_t_input = scaler.transform(train_input)
scaled_p_input = scaler.transform(predict_input)

from sklearn.model_selection import StratifiedKFold, cross_validate, KFold
model = DecisionTreeRegressor()
# splitter = StratifiedKFold(n_splits=10,shuffle=True)
splitter = KFold(n_splits=10,shuffle=True)
scores = cross_validate(model,scaled_t_input,train_target,cv=splitter)
print(np.mean(scores['test_score']))

from sklearn.linear_model import LinearRegression
splitter = KFold(n_splits=10,shuffle=True)
scores = cross_validate(LinearRegression(),scaled_t_input,train_target,cv=splitter)
print(np.mean(scores['test_score']))

from sklearn.preprocessing import PolynomialFeatures
ploy = PolynomialFeatures()
ploy.fit(scaled_t_input)
pst_input = ploy.transform(scaled_t_input)

splitter = KFold(n_splits=10,shuffle=True)
scores = cross_validate(model,pst_input,train_target,cv=splitter)
print(np.mean(scores['test_score']))

splitter = KFold(n_splits=10,shuffle=True)
scores = cross_validate(LinearRegression(),pst_input,train_target,cv=splitter)
print(np.mean(scores['test_score']))

from sklearn.linear_model import Lasso
splitter = KFold(n_splits=10,shuffle=True)
scores = cross_validate(Lasso(),scaled_t_input,train_target,cv=splitter)
print(np.mean(scores['test_score']))

train_input.columns

adj_train_input = train_input.drop(columns=["Parch","Ticket","Name","Sex"])
scaler = StandardScaler()
scaler.fit(adj_train_input)
adj_scaled_input = scaler.transform(adj_train_input)

splitter = KFold(n_splits=10,shuffle=True)
scores = cross_validate(model,adj_scaled_input,train_target,cv=splitter)
print(np.mean(scores['test_score']))

print(adj_train_input)

b_list = []
i2b = lambda x:("".join(["0" for i in range(0,10-len("{0:b}".format(x)))])+"{0:b}".format(x)).strip()
for i in range(1,2**10-1):
  b_list.append(i2b(i))
columns = train_input.columns
columns_set = []
for b in b_list:
  s = []
  for j,i in enumerate(b):
    if i == "0":
      pass
    else:
      s.append(columns[j])
  columns_set.append(s)
print(columns_set)

arg_list = []
for c in columns_set:
  adj_train_input = train_input.drop(columns=c)
  scaler = StandardScaler()
  scaler.fit(adj_train_input)
  adj_scaled_input = scaler.transform(adj_train_input)
  splitter = KFold(n_splits=10,shuffle=True)
  scores = cross_validate(model,adj_scaled_input,train_target,cv=splitter)
  arg_list.append(np.mean(scores['test_score']))
arg_list = np.array(arg_list)
maxarg = np.argmax(arg_list)
print(np.argmax(arg_list))  
print(columns_set[maxarg])
print(arg_list[maxarg])

new_train_input = train_input.drop(columns=columns_set[maxarg])
new_predict_input = predict_input.drop(columns=columns_set[maxarg])
scaler = StandardScaler()
scaler.fit(new_train_input)
adj_scaled_input = scaler.transform(new_train_input)
adj_scaled_predict_input = scaler.transform(new_predict_input)
predict_model = DecisionTreeRegressor()
predict_model.fit(adj_scaled_input,train_target)
age_predict = predict_model.predict(adj_scaled_predict_input)
print(age_predict)

print(predict_input.index)

for i,j in zip(predict_input.index,age_predict):
  titanic['Age'][i] = j

titanic.info()

scaler = StandardScaler()
train_data = titanic.drop(columns=["Survived"])
train_data_target = titanic["Survived"]
scaler.fit(train_data)
scaled_train_data = scaler.transform(train_data)

from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import BaggingClassifier
classifier = BaggingClassifier(base_estimator=RandomForestClassifier(n_jobs=-1),n_estimators=10)
splitter = KFold(n_splits=10,shuffle=True)
scores = cross_validate(classifier,scaled_train_data,train_data_target,cv=splitter)
print(np.mean(scores["test_score"]))

test_titanic = pd.read_csv("/content/test.csv")

final_model =  BaggingClassifier(base_estimator=RandomForestClassifier(n_jobs=-1),n_estimators=10)
final_model.fit(scaled_train_data,train_data_target)

test_titanic.info()

test_titanic["Sex"] = test_titanic["Sex"].map({"male":1,"female":0})

test_family_name_set = set(test_titanic["Name"].map(lambda x: x.split(",")[0]))
first_class_index = test_titanic["Pclass"] == 1
first_class  = test_titanic[first_class_index]

second_class_index = test_titanic["Pclass"] == 2
second_class  = test_titanic[second_class_index]

third_class_index = test_titanic["Pclass"] == 3
third_class  = test_titanic[third_class_index]

first_name_set = set(first_class["Name"].map(lambda x: x.split(",")[0]))
first_name_dict = classNames(first_class,list(first_name_set))


second_name_set = set(second_class["Name"].map(lambda x: x.split(",")[0]))
second_name_dict = classNames(second_class,list(second_name_set))

third_name_set = set(third_class["Name"].map(lambda x: x.split(",")[0]))
third_name_dict = classNames(third_class,list(third_name_set))

class_name_list = list(first_name_dict.values())
class_name_list.extend(list(second_name_dict.values()))
class_name_list.extend(list(third_name_dict.values()))
Name = list(range(0,titanic["Name"].size))
for i,num in enumerate(class_name_list):
  if i >= len(first_name_dict):
    i+=100
    if i >= len(first_name_dict)+len(second_name_dict):
      i+=100
  for index in num:
    Name[index] = i+1
test_titanic["Name"] = pd.Series(Name)

test_titanic.drop(columns=["Cabin"],inplace=True)

print(test_titanic['Embarked'].unique())
convert_dict = {"S":1,"C":2,"Q":3}
test_titanic["Embarked"] = test_titanic["Embarked"].map(lambda x:1 if x is np.nan else convert_dict[x])

ticket_list = []
adder = test_titanic["Ticket"].map(ticket2int).mean()
for i in range(0,test_titanic["Ticket"].size):
  pclass = test_titanic.loc[i,"Pclass"]
  if pclass == 2:
    ticket = ticket2int(test_titanic["Ticket"][i])+adder
  elif pclass == 3:
    ticket = ticket2int(test_titanic["Ticket"][i])+adder*2
  else:
    ticket = ticket2int(test_titanic["Ticket"][i])
  ticket_list.append(ticket)  

test_titanic["Ticket"] = pd.Series(ticket_list)

test_titanic.info()

new_test_titanic = test_titanic.fillna(-1)
test_index = new_test_titanic.index[new_test_titanic["Age"] == -1]
print(len(test_index))
print(test_index)

predict = new_test_titanic.iloc[test_index,:]
predict_input = predict.drop(columns=["Age"])

train_index = new_test_titanic.index[new_test_titanic["Age"] != -1]
print(len(train_index))
print(train_index)

train =  new_test_titanic.iloc[train_index,:]

train_input = train.drop(columns=["Age"])
train_target = train["Age"]

b_list = []
i2b = lambda x:("".join(["0" for i in range(0,9-len("{0:b}".format(x)))])+"{0:b}".format(x)).strip()
for i in range(1,2**9-1):
  b_list.append(i2b(i))
columns = train_input.columns
columns_set = []
for b in b_list:
  s = []
  for j,i in enumerate(b):
    if i == "0":
      pass
    else:
      s.append(columns[j])
  columns_set.append(s)
print(columns_set)

arg_list = []
for c in columns_set:
  adj_train_input = train_input.drop(columns=c)
  scaler = StandardScaler()
  scaler.fit(adj_train_input)
  adj_scaled_input = scaler.transform(adj_train_input)
  splitter = KFold(n_splits=10,shuffle=True)
  scores = cross_validate(model,adj_scaled_input,train_target,cv=splitter)
  arg_list.append(np.mean(scores['test_score']))
arg_list = np.array(arg_list)
maxarg = np.argmax(arg_list)
print(np.argmax(arg_list))  
print(columns_set[maxarg])
print(arg_list[maxarg])

new_train_input = train_input.drop(columns=columns_set[maxarg])
new_predict_input = predict_input.drop(columns=columns_set[maxarg])
scaler = StandardScaler()
scaler.fit(new_train_input)
adj_scaled_input = scaler.transform(new_train_input)
adj_scaled_predict_input = scaler.transform(new_predict_input)
predict_model = DecisionTreeRegressor()
predict_model.fit(adj_scaled_input,train_target)
age_predict = predict_model.predict(adj_scaled_predict_input)
print(age_predict)

for i,j in zip(predict_input.index,age_predict):
  test_titanic['Age'][i] = j

test_titanic.info()

new_test_titanic = test_titanic.fillna(test_titanic["Fare"].mean())
new_test_titanic.info()

scaler = StandardScaler()
scaler.fit(new_test_titanic)
scaled_new_test_titanic = scaler.transform(new_test_titanic)

result = final_model.predict(scaled_new_test_titanic)
result_titanic = pd.read_csv("/content/test.csv")
result_titanic['Survived'] = result
result_titanic = result_titanic.loc[:,["Survived","PassengerId"]]
print(result_titanic)
result_titanic.to_csv("/content/predic_result.csv",index = False)

