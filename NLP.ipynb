{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwGBrwt3GkAs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(20,1),name=\"input\")\n",
        "outputs = tf.keras.layers.Dense(units = 10, activation=\"softmax\", name=\"output_softmax\")(input)\n",
        "model_1 = tf.keras.Model(inputs=intpus,outputs=outputs)\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "mY82wRl1U_mn",
        "outputId": "f957468e-d080-4cc4-ed26-69920330154a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b0f0468d9950>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output_softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# have a `shape` attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Inputs to a layer should be tensors. Got: {x}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Inputs to a layer should be tensors. Got: <bound method Kernel.raw_input of <google.colab._kernel.Kernel object at 0x7f98ed5dec50>>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "_fgfQlR4VD-0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape = 20\n",
        "input = tf.keras.layers.Input(shape = shape,name=\"input\")\n",
        "output = tf.keras.layers.Dense(units=10,activation=\"softmax\", name=\"output\")(input)\n",
        "model = tf.keras.Model(inputs=input,outputs = output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPLjK5WaXHnV",
        "outputId": "0688df6d-124f-4a35-82a0-642357e99618"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 20)]              0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                210       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 210\n",
            "Trainable params: 210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 20\n",
        "inputs = tf.keras.layers.Input(shape=input_size, name=\"inputs\")\n",
        "dropout = tf.keras.layers.Dropout(rate = 0.2,name=\"dropout\")(inputs)\n",
        "hidden = tf.keras.layers.Dense(units=10,activation=\"relu\",name=\"hidden\")(dropout)\n",
        "output = tf.keras.layers.Dense(units=2,activation=\"softmax\",name=\"output\")(hidden)\n",
        "\n",
        "model_3 = tf.keras.Model(inputs=inputs,outputs=output)\n",
        "\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGCx69YKXhth",
        "outputId": "8636e8ff-70c5-4028-fee6-47d46a309e55"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " inputs (InputLayer)         [(None, 20)]              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20)                0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 10)                210       \n",
            "                                                                 \n",
            " output (Dense)              (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 232\n",
            "Trainable params: 232\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1D convolution\n",
        "input_size = (20,1)\n",
        "input = tf.keras.layers.Input(shape = input_size)\n",
        "conv = tf.keras.layers.Conv1D(filters = 10, kernel_size=3,padding=\"same\",activation=\"relu\")(input)"
      ],
      "metadata": {
        "id": "0EbLb1GLg5MZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = tf.keras.Model(inputs=input,outputs=conv)\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7VJ9DFfktzv",
        "outputId": "88768ee7-d520-4909-c6f8-5215ee251881"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20, 1)]           0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 20, 10)            40        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40\n",
            "Trainable params: 40\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = (20,1)\n",
        "inputs = tf.keras.layers.Input(shape=input_size,name=\"input\")\n",
        "dropout = tf.keras.layers.Dropout(rate=0.2,name=\"dropout\")(inputs)\n",
        "conv = tf.keras.layers.Conv1D(filters=10,kernel_size=3,padding=\"same\",activation=\"relu\",name=\"Conv\")(dropout)\n",
        "max_pool = tf.keras.layers.MaxPool1D(pool_size=3)(conv)\n",
        "flatten = tf.keras.layers.Flatten()(max_pool)\n",
        "hidden = tf.keras.layers.Dense(units=50,activation=\"relu\",name=\"hidden\")(flatten)\n",
        "outputs= tf.keras.layers.Dense(units=10,activation=\"softmax\")(hidden)\n",
        "model = tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAgB8ro7k51a",
        "outputId": "4e56fc00-0f91-45ce-a4b6-228e18d3c9e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 20, 1)]           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 20, 1)             0         \n",
            "                                                                 \n",
            " Conv (Conv1D)               (None, 20, 10)            40        \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 6, 10)            0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 60)                0         \n",
            "                                                                 \n",
            " hidden (Dense)              (None, 50)                3050      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                510       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,600\n",
            "Trainable params: 3,600\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(name = \"Sequential_API\")\n",
        "model.add(tf.keras.layers.Input(shape=(32,), name=\"input\"))\n",
        "model.add(tf.keras.layers.Dense(units=64,activation=\"relu\",name=\"Dense1\"))\n",
        "model.add(tf.keras.layers.Dense(units=64,activation=\"relu\",name=\"Dense2\"))\n",
        "model.add(tf.keras.layers.Dense(units=10,activation=\"softmax\",name=\"output\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BqCjEMWrd5k",
        "outputId": "1bd692d0-87cb-4579-93ff-216b9f7d5282"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Sequential_API\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " Dense1 (Dense)              (None, 64)                2112      \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 64)                4160      \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,922\n",
            "Trainable params: 6,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(32,),name=\"input\")\n",
        "Dense1 = tf.keras.layers.Dense(units = 64,activation=\"relu\",name=\"dense1\")(inputs)\n",
        "Dense2 = tf.keras.layers.Dense(units=64,activation=\"relu\",name=\"dense2\")(Dense1)\n",
        "outputs = tf.keras.layers.Dense(units=10,activation=\"softmax\",name=\"outputs\")(Dense2)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs,outputs=outputs)"
      ],
      "metadata": {
        "id": "CaPEL0GmLwEI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Customlayer(tf.keras.layers.Layer):\n",
        "  def __init__(self,hidden1,hidden2,output_layer):\n",
        "    super(Customlayer,self).__init__()\n",
        "    self.hidden1 = hidden1\n",
        "    self.hidden2 = hidden2\n",
        "    self.output_layer = output_layer\n",
        "\n",
        "  def build(self,inputs):\n",
        "    self.dense_layer1 = tf.keras.layers.Dense(units = self.hidden1,activation=\"relu\",name = \"Dense1\")\n",
        "    self.dense_layers = tf.keras.layers.Dense(units = self.hidden2,activation=\"relu\",name=\"Dense2\")\n",
        "    self.output_layers = tf.keras.layers.Dense(units = self.output_layer,activation=\"softmax\",name=\"output\")\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x = self.dense_layer1(inputs)\n",
        "    x = self.dense_layers(x)\n",
        "\n",
        "    return self.output_layers(x)    "
      ],
      "metadata": {
        "id": "X9bi_a80SgP2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(name=\"Custom_layer\")\n",
        "model.add(tf.keras.layers.Input(shape=(32,)))\n",
        "model.add(Customlayer(64,64,10))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKtJzOcuU-gj",
        "outputId": "723f2ee6-2aac-4dee-f04d-485b2063a5de"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Custom_layer\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " customlayer_2 (Customlayer)  (None, 10)               6922      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,922\n",
            "Trainable params: 6,922\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data = np.loadtxt(\"/pima-indians-diabetes.csv\",delimiter=',')"
      ],
      "metadata": {
        "id": "Wia7TZtIVWGV"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = data[:,0:8]\n",
        "y = data[:,-1]"
      ],
      "metadata": {
        "id": "JnQ0LTfIaue8"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt1L2-U0a7xn",
        "outputId": "6c0972d6-8b99-4c12-b5a0-0a14ca76db27"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6912"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential(name=\"Sequential\")"
      ],
      "metadata": {
        "id": "shDEEoQfa_At"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(tf.keras.layers.Input(shape=(8,),name=\"input\"))\n",
        "model.add(tf.keras.layers.Dense(units=12,activation='relu',name='dense1'))\n",
        "model.add(tf.keras.layers.Dense(units=8,activation='relu',name='dense2'))\n",
        "model.add(tf.keras.layers.Dense(units=1,activation='sigmoid',name='output'))"
      ],
      "metadata": {
        "id": "dOCWgDpKbMnH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"binary_crossentropy\",optimizer='adam',metrics=['acc'])\n",
        "model.fit(x,y,batch_size=6912,epochs=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_aIrw1sbgqo",
        "outputId": "2be0b9fa-15f5-4c92-e1eb-1a428e63f662"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.4772 - acc: 0.7721\n",
            "Epoch 2/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4798 - acc: 0.7669\n",
            "Epoch 3/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4932 - acc: 0.7669\n",
            "Epoch 4/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4784 - acc: 0.7760\n",
            "Epoch 5/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4838 - acc: 0.7591\n",
            "Epoch 6/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4861 - acc: 0.7578\n",
            "Epoch 7/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4796 - acc: 0.7604\n",
            "Epoch 8/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4779 - acc: 0.7799\n",
            "Epoch 9/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4819 - acc: 0.7734\n",
            "Epoch 10/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4822 - acc: 0.7734\n",
            "Epoch 11/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4788 - acc: 0.7721\n",
            "Epoch 12/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4773 - acc: 0.7682\n",
            "Epoch 13/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4791 - acc: 0.7617\n",
            "Epoch 14/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4800 - acc: 0.7604\n",
            "Epoch 15/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4784 - acc: 0.7656\n",
            "Epoch 16/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4770 - acc: 0.7656\n",
            "Epoch 17/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4775 - acc: 0.7812\n",
            "Epoch 18/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4787 - acc: 0.7799\n",
            "Epoch 19/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4784 - acc: 0.7773\n",
            "Epoch 20/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4771 - acc: 0.7839\n",
            "Epoch 21/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4768 - acc: 0.7669\n",
            "Epoch 22/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4775 - acc: 0.7656\n",
            "Epoch 23/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4778 - acc: 0.7656\n",
            "Epoch 24/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4772 - acc: 0.7656\n",
            "Epoch 25/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4765 - acc: 0.7708\n",
            "Epoch 26/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4767 - acc: 0.7799\n",
            "Epoch 27/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4772 - acc: 0.7799\n",
            "Epoch 28/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4770 - acc: 0.7799\n",
            "Epoch 29/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4766 - acc: 0.7786\n",
            "Epoch 30/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4765 - acc: 0.7682\n",
            "Epoch 31/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4767 - acc: 0.7643\n",
            "Epoch 32/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4766 - acc: 0.7643\n",
            "Epoch 33/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4763 - acc: 0.7669\n",
            "Epoch 34/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4762 - acc: 0.7760\n",
            "Epoch 35/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4764 - acc: 0.7773\n",
            "Epoch 36/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4764 - acc: 0.7799\n",
            "Epoch 37/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4762 - acc: 0.7773\n",
            "Epoch 38/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4761 - acc: 0.7734\n",
            "Epoch 39/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4762 - acc: 0.7682\n",
            "Epoch 40/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4762 - acc: 0.7656\n",
            "Epoch 41/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4760 - acc: 0.7682\n",
            "Epoch 42/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4759 - acc: 0.7721\n",
            "Epoch 43/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4759 - acc: 0.7773\n",
            "Epoch 44/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4759 - acc: 0.7773\n",
            "Epoch 45/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4758 - acc: 0.7773\n",
            "Epoch 46/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4757 - acc: 0.7721\n",
            "Epoch 47/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4757 - acc: 0.7695\n",
            "Epoch 48/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4757 - acc: 0.7669\n",
            "Epoch 49/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4756 - acc: 0.7708\n",
            "Epoch 50/700\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4755 - acc: 0.7747\n",
            "Epoch 51/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4755 - acc: 0.7760\n",
            "Epoch 52/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4754 - acc: 0.7786\n",
            "Epoch 53/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4754 - acc: 0.7760\n",
            "Epoch 54/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4753 - acc: 0.7721\n",
            "Epoch 55/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4753 - acc: 0.7695\n",
            "Epoch 56/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4752 - acc: 0.7695\n",
            "Epoch 57/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4751 - acc: 0.7747\n",
            "Epoch 58/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4751 - acc: 0.7760\n",
            "Epoch 59/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4751 - acc: 0.7760\n",
            "Epoch 60/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4750 - acc: 0.7760\n",
            "Epoch 61/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4750 - acc: 0.7760\n",
            "Epoch 62/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4749 - acc: 0.7708\n",
            "Epoch 63/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4749 - acc: 0.7708\n",
            "Epoch 64/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4748 - acc: 0.7708\n",
            "Epoch 65/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4748 - acc: 0.7747\n",
            "Epoch 66/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4747 - acc: 0.7747\n",
            "Epoch 67/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4747 - acc: 0.7760\n",
            "Epoch 68/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4746 - acc: 0.7773\n",
            "Epoch 69/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4746 - acc: 0.7773\n",
            "Epoch 70/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4745 - acc: 0.7760\n",
            "Epoch 71/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4745 - acc: 0.7747\n",
            "Epoch 72/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4745 - acc: 0.7708\n",
            "Epoch 73/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4744 - acc: 0.7721\n",
            "Epoch 74/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4743 - acc: 0.7734\n",
            "Epoch 75/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4743 - acc: 0.7747\n",
            "Epoch 76/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4742 - acc: 0.7760\n",
            "Epoch 77/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4742 - acc: 0.7747\n",
            "Epoch 78/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4741 - acc: 0.7734\n",
            "Epoch 79/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4741 - acc: 0.7721\n",
            "Epoch 80/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4741 - acc: 0.7721\n",
            "Epoch 81/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4740 - acc: 0.7747\n",
            "Epoch 82/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4740 - acc: 0.7747\n",
            "Epoch 83/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4739 - acc: 0.7760\n",
            "Epoch 84/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4739 - acc: 0.7760\n",
            "Epoch 85/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4738 - acc: 0.7734\n",
            "Epoch 86/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4738 - acc: 0.7747\n",
            "Epoch 87/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4737 - acc: 0.7734\n",
            "Epoch 88/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4737 - acc: 0.7734\n",
            "Epoch 89/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4736 - acc: 0.7760\n",
            "Epoch 90/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4736 - acc: 0.7760\n",
            "Epoch 91/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4735 - acc: 0.7760\n",
            "Epoch 92/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4735 - acc: 0.7760\n",
            "Epoch 93/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4734 - acc: 0.7760\n",
            "Epoch 94/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4733 - acc: 0.7721\n",
            "Epoch 95/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4733 - acc: 0.7747\n",
            "Epoch 96/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4732 - acc: 0.7760\n",
            "Epoch 97/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4732 - acc: 0.7760\n",
            "Epoch 98/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4731 - acc: 0.7760\n",
            "Epoch 99/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4731 - acc: 0.7747\n",
            "Epoch 100/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4730 - acc: 0.7747\n",
            "Epoch 101/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4730 - acc: 0.7747\n",
            "Epoch 102/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4730 - acc: 0.7760\n",
            "Epoch 103/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4729 - acc: 0.7760\n",
            "Epoch 104/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4729 - acc: 0.7760\n",
            "Epoch 105/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4728 - acc: 0.7760\n",
            "Epoch 106/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4727 - acc: 0.7747\n",
            "Epoch 107/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4727 - acc: 0.7747\n",
            "Epoch 108/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4727 - acc: 0.7747\n",
            "Epoch 109/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4726 - acc: 0.7747\n",
            "Epoch 110/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4725 - acc: 0.7747\n",
            "Epoch 111/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4725 - acc: 0.7747\n",
            "Epoch 112/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4725 - acc: 0.7747\n",
            "Epoch 113/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4724 - acc: 0.7747\n",
            "Epoch 114/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4724 - acc: 0.7734\n",
            "Epoch 115/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4723 - acc: 0.7721\n",
            "Epoch 116/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4723 - acc: 0.7734\n",
            "Epoch 117/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4722 - acc: 0.7747\n",
            "Epoch 118/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4722 - acc: 0.7734\n",
            "Epoch 119/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4721 - acc: 0.7747\n",
            "Epoch 120/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4721 - acc: 0.7773\n",
            "Epoch 121/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4721 - acc: 0.7747\n",
            "Epoch 122/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4720 - acc: 0.7747\n",
            "Epoch 123/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4719 - acc: 0.7734\n",
            "Epoch 124/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4719 - acc: 0.7747\n",
            "Epoch 125/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4718 - acc: 0.7747\n",
            "Epoch 126/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4718 - acc: 0.7773\n",
            "Epoch 127/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4717 - acc: 0.7773\n",
            "Epoch 128/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4716 - acc: 0.7747\n",
            "Epoch 129/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4716 - acc: 0.7747\n",
            "Epoch 130/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4716 - acc: 0.7747\n",
            "Epoch 131/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4715 - acc: 0.7773\n",
            "Epoch 132/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4715 - acc: 0.7773\n",
            "Epoch 133/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4714 - acc: 0.7773\n",
            "Epoch 134/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4713 - acc: 0.7747\n",
            "Epoch 135/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4713 - acc: 0.7747\n",
            "Epoch 136/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4712 - acc: 0.7747\n",
            "Epoch 137/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4712 - acc: 0.7773\n",
            "Epoch 138/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4712 - acc: 0.7773\n",
            "Epoch 139/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4711 - acc: 0.7773\n",
            "Epoch 140/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4711 - acc: 0.7747\n",
            "Epoch 141/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4710 - acc: 0.7747\n",
            "Epoch 142/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4710 - acc: 0.7747\n",
            "Epoch 143/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4709 - acc: 0.7773\n",
            "Epoch 144/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4709 - acc: 0.7773\n",
            "Epoch 145/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4708 - acc: 0.7773\n",
            "Epoch 146/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4708 - acc: 0.7760\n",
            "Epoch 147/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4707 - acc: 0.7760\n",
            "Epoch 148/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4706 - acc: 0.7786\n",
            "Epoch 149/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4706 - acc: 0.7773\n",
            "Epoch 150/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4705 - acc: 0.7786\n",
            "Epoch 151/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4705 - acc: 0.7747\n",
            "Epoch 152/700\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4704 - acc: 0.7747\n",
            "Epoch 153/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4704 - acc: 0.7747\n",
            "Epoch 154/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4703 - acc: 0.7747\n",
            "Epoch 155/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4703 - acc: 0.7773\n",
            "Epoch 156/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4702 - acc: 0.7760\n",
            "Epoch 157/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4702 - acc: 0.7747\n",
            "Epoch 158/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4701 - acc: 0.7760\n",
            "Epoch 159/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4700 - acc: 0.7773\n",
            "Epoch 160/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4700 - acc: 0.7786\n",
            "Epoch 161/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4699 - acc: 0.7760\n",
            "Epoch 162/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4699 - acc: 0.7773\n",
            "Epoch 163/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4698 - acc: 0.7799\n",
            "Epoch 164/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4697 - acc: 0.7786\n",
            "Epoch 165/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4697 - acc: 0.7799\n",
            "Epoch 166/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4696 - acc: 0.7799\n",
            "Epoch 167/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4695 - acc: 0.7773\n",
            "Epoch 168/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4695 - acc: 0.7760\n",
            "Epoch 169/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4694 - acc: 0.7786\n",
            "Epoch 170/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4694 - acc: 0.7799\n",
            "Epoch 171/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4693 - acc: 0.7786\n",
            "Epoch 172/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4692 - acc: 0.7786\n",
            "Epoch 173/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4692 - acc: 0.7786\n",
            "Epoch 174/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4691 - acc: 0.7786\n",
            "Epoch 175/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4691 - acc: 0.7786\n",
            "Epoch 176/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4690 - acc: 0.7760\n",
            "Epoch 177/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4689 - acc: 0.7799\n",
            "Epoch 178/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4688 - acc: 0.7799\n",
            "Epoch 179/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4688 - acc: 0.7773\n",
            "Epoch 180/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4687 - acc: 0.7773\n",
            "Epoch 181/700\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.4687 - acc: 0.7799\n",
            "Epoch 182/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4686 - acc: 0.7799\n",
            "Epoch 183/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4685 - acc: 0.7773\n",
            "Epoch 184/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4681 - acc: 0.7773\n",
            "Epoch 185/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4677 - acc: 0.7799\n",
            "Epoch 186/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4674 - acc: 0.7839\n",
            "Epoch 187/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4669 - acc: 0.7812\n",
            "Epoch 188/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4669 - acc: 0.7773\n",
            "Epoch 189/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4668 - acc: 0.7799\n",
            "Epoch 190/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4668 - acc: 0.7839\n",
            "Epoch 191/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4667 - acc: 0.7839\n",
            "Epoch 192/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4666 - acc: 0.7799\n",
            "Epoch 193/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4666 - acc: 0.7773\n",
            "Epoch 194/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4665 - acc: 0.7786\n",
            "Epoch 195/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4665 - acc: 0.7826\n",
            "Epoch 196/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4664 - acc: 0.7812\n",
            "Epoch 197/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4663 - acc: 0.7773\n",
            "Epoch 198/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4663 - acc: 0.7760\n",
            "Epoch 199/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4662 - acc: 0.7812\n",
            "Epoch 200/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4661 - acc: 0.7812\n",
            "Epoch 201/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4660 - acc: 0.7812\n",
            "Epoch 202/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4660 - acc: 0.7786\n",
            "Epoch 203/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4659 - acc: 0.7826\n",
            "Epoch 204/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4659 - acc: 0.7826\n",
            "Epoch 205/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4658 - acc: 0.7773\n",
            "Epoch 206/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4657 - acc: 0.7773\n",
            "Epoch 207/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4656 - acc: 0.7799\n",
            "Epoch 208/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4656 - acc: 0.7826\n",
            "Epoch 209/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4655 - acc: 0.7826\n",
            "Epoch 210/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4655 - acc: 0.7786\n",
            "Epoch 211/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4654 - acc: 0.7786\n",
            "Epoch 212/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4653 - acc: 0.7826\n",
            "Epoch 213/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4652 - acc: 0.7812\n",
            "Epoch 214/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4652 - acc: 0.7812\n",
            "Epoch 215/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4651 - acc: 0.7826\n",
            "Epoch 216/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4651 - acc: 0.7826\n",
            "Epoch 217/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4650 - acc: 0.7799\n",
            "Epoch 218/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4649 - acc: 0.7812\n",
            "Epoch 219/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4648 - acc: 0.7839\n",
            "Epoch 220/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4648 - acc: 0.7839\n",
            "Epoch 221/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4647 - acc: 0.7839\n",
            "Epoch 222/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4647 - acc: 0.7812\n",
            "Epoch 223/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4646 - acc: 0.7826\n",
            "Epoch 224/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4646 - acc: 0.7839\n",
            "Epoch 225/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4645 - acc: 0.7839\n",
            "Epoch 226/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4645 - acc: 0.7839\n",
            "Epoch 227/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4644 - acc: 0.7839\n",
            "Epoch 228/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4643 - acc: 0.7852\n",
            "Epoch 229/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4643 - acc: 0.7852\n",
            "Epoch 230/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4642 - acc: 0.7812\n",
            "Epoch 231/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4641 - acc: 0.7852\n",
            "Epoch 232/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4641 - acc: 0.7865\n",
            "Epoch 233/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4640 - acc: 0.7852\n",
            "Epoch 234/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4640 - acc: 0.7799\n",
            "Epoch 235/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4639 - acc: 0.7812\n",
            "Epoch 236/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4638 - acc: 0.7878\n",
            "Epoch 237/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4638 - acc: 0.7878\n",
            "Epoch 238/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4637 - acc: 0.7852\n",
            "Epoch 239/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4637 - acc: 0.7799\n",
            "Epoch 240/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4636 - acc: 0.7852\n",
            "Epoch 241/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4636 - acc: 0.7891\n",
            "Epoch 242/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4634 - acc: 0.7852\n",
            "Epoch 243/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4635 - acc: 0.7812\n",
            "Epoch 244/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4633 - acc: 0.7852\n",
            "Epoch 245/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4633 - acc: 0.7878\n",
            "Epoch 246/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4632 - acc: 0.7852\n",
            "Epoch 247/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4631 - acc: 0.7799\n",
            "Epoch 248/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4631 - acc: 0.7826\n",
            "Epoch 249/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4630 - acc: 0.7878\n",
            "Epoch 250/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4630 - acc: 0.7891\n",
            "Epoch 251/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4629 - acc: 0.7865\n",
            "Epoch 252/700\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.4629 - acc: 0.7773\n",
            "Epoch 253/700\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.4627 - acc: 0.7865\n",
            "Epoch 254/700\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4627 - acc: 0.7878\n",
            "Epoch 255/700\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.4627 - acc: 0.7878\n",
            "Epoch 256/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4626 - acc: 0.7852\n",
            "Epoch 257/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4625 - acc: 0.7826\n",
            "Epoch 258/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4625 - acc: 0.7865\n",
            "Epoch 259/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4625 - acc: 0.7865\n",
            "Epoch 260/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4624 - acc: 0.7865\n",
            "Epoch 261/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4623 - acc: 0.7852\n",
            "Epoch 262/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4622 - acc: 0.7852\n",
            "Epoch 263/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4622 - acc: 0.7878\n",
            "Epoch 264/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4622 - acc: 0.7891\n",
            "Epoch 265/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4620 - acc: 0.7852\n",
            "Epoch 266/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4620 - acc: 0.7826\n",
            "Epoch 267/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4619 - acc: 0.7852\n",
            "Epoch 268/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4619 - acc: 0.7891\n",
            "Epoch 269/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4618 - acc: 0.7865\n",
            "Epoch 270/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4618 - acc: 0.7839\n",
            "Epoch 271/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4617 - acc: 0.7865\n",
            "Epoch 272/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4616 - acc: 0.7891\n",
            "Epoch 273/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4615 - acc: 0.7865\n",
            "Epoch 274/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4615 - acc: 0.7839\n",
            "Epoch 275/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4614 - acc: 0.7852\n",
            "Epoch 276/700\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4613 - acc: 0.7878\n",
            "Epoch 277/700\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.4612 - acc: 0.7878\n",
            "Epoch 278/700\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.4612 - acc: 0.7852\n",
            "Epoch 279/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4611 - acc: 0.7839\n",
            "Epoch 280/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4610 - acc: 0.7865\n",
            "Epoch 281/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4610 - acc: 0.7878\n",
            "Epoch 282/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4609 - acc: 0.7878\n",
            "Epoch 283/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4608 - acc: 0.7839\n",
            "Epoch 284/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4608 - acc: 0.7839\n",
            "Epoch 285/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4607 - acc: 0.7865\n",
            "Epoch 286/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4606 - acc: 0.7878\n",
            "Epoch 287/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4605 - acc: 0.7878\n",
            "Epoch 288/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4605 - acc: 0.7878\n",
            "Epoch 289/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4604 - acc: 0.7878\n",
            "Epoch 290/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4603 - acc: 0.7878\n",
            "Epoch 291/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4603 - acc: 0.7878\n",
            "Epoch 292/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4602 - acc: 0.7839\n",
            "Epoch 293/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4601 - acc: 0.7878\n",
            "Epoch 294/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4601 - acc: 0.7878\n",
            "Epoch 295/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4600 - acc: 0.7878\n",
            "Epoch 296/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4600 - acc: 0.7865\n",
            "Epoch 297/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4599 - acc: 0.7878\n",
            "Epoch 298/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4599 - acc: 0.7943\n",
            "Epoch 299/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4597 - acc: 0.7878\n",
            "Epoch 300/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4597 - acc: 0.7852\n",
            "Epoch 301/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4596 - acc: 0.7878\n",
            "Epoch 302/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4596 - acc: 0.7891\n",
            "Epoch 303/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4594 - acc: 0.7878\n",
            "Epoch 304/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4594 - acc: 0.7878\n",
            "Epoch 305/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4593 - acc: 0.7891\n",
            "Epoch 306/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4592 - acc: 0.7891\n",
            "Epoch 307/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4592 - acc: 0.7891\n",
            "Epoch 308/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4592 - acc: 0.7891\n",
            "Epoch 309/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4591 - acc: 0.7917\n",
            "Epoch 310/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4590 - acc: 0.7891\n",
            "Epoch 311/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4590 - acc: 0.7865\n",
            "Epoch 312/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4589 - acc: 0.7891\n",
            "Epoch 313/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4589 - acc: 0.7930\n",
            "Epoch 314/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4588 - acc: 0.7891\n",
            "Epoch 315/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4588 - acc: 0.7865\n",
            "Epoch 316/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4587 - acc: 0.7878\n",
            "Epoch 317/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4587 - acc: 0.7930\n",
            "Epoch 318/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4585 - acc: 0.7943\n",
            "Epoch 319/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4586 - acc: 0.7826\n",
            "Epoch 320/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4584 - acc: 0.7904\n",
            "Epoch 321/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4584 - acc: 0.7930\n",
            "Epoch 322/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4583 - acc: 0.7917\n",
            "Epoch 323/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4582 - acc: 0.7891\n",
            "Epoch 324/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4581 - acc: 0.7904\n",
            "Epoch 325/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4581 - acc: 0.7930\n",
            "Epoch 326/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4580 - acc: 0.7904\n",
            "Epoch 327/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4579 - acc: 0.7917\n",
            "Epoch 328/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4579 - acc: 0.7917\n",
            "Epoch 329/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4578 - acc: 0.7943\n",
            "Epoch 330/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4577 - acc: 0.7917\n",
            "Epoch 331/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4577 - acc: 0.7904\n",
            "Epoch 332/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4576 - acc: 0.7956\n",
            "Epoch 333/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4576 - acc: 0.7943\n",
            "Epoch 334/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4575 - acc: 0.7917\n",
            "Epoch 335/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4574 - acc: 0.7930\n",
            "Epoch 336/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4574 - acc: 0.7943\n",
            "Epoch 337/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4573 - acc: 0.7930\n",
            "Epoch 338/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4573 - acc: 0.7904\n",
            "Epoch 339/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4572 - acc: 0.7904\n",
            "Epoch 340/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4571 - acc: 0.7930\n",
            "Epoch 341/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4571 - acc: 0.7904\n",
            "Epoch 342/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4570 - acc: 0.7904\n",
            "Epoch 343/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4570 - acc: 0.7956\n",
            "Epoch 344/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4569 - acc: 0.7943\n",
            "Epoch 345/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4568 - acc: 0.7943\n",
            "Epoch 346/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4567 - acc: 0.7943\n",
            "Epoch 347/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4567 - acc: 0.7943\n",
            "Epoch 348/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4566 - acc: 0.7917\n",
            "Epoch 349/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4566 - acc: 0.7943\n",
            "Epoch 350/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4565 - acc: 0.7943\n",
            "Epoch 351/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4565 - acc: 0.7904\n",
            "Epoch 352/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4564 - acc: 0.7917\n",
            "Epoch 353/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4563 - acc: 0.7930\n",
            "Epoch 354/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4563 - acc: 0.7917\n",
            "Epoch 355/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4563 - acc: 0.7943\n",
            "Epoch 356/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4562 - acc: 0.7943\n",
            "Epoch 357/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4561 - acc: 0.7904\n",
            "Epoch 358/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4561 - acc: 0.7917\n",
            "Epoch 359/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4560 - acc: 0.7930\n",
            "Epoch 360/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4559 - acc: 0.7943\n",
            "Epoch 361/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4559 - acc: 0.7943\n",
            "Epoch 362/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4558 - acc: 0.7943\n",
            "Epoch 363/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4557 - acc: 0.7943\n",
            "Epoch 364/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4557 - acc: 0.7943\n",
            "Epoch 365/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4556 - acc: 0.7930\n",
            "Epoch 366/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4556 - acc: 0.7943\n",
            "Epoch 367/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4555 - acc: 0.7930\n",
            "Epoch 368/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4554 - acc: 0.7943\n",
            "Epoch 369/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4554 - acc: 0.7917\n",
            "Epoch 370/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4553 - acc: 0.7930\n",
            "Epoch 371/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4553 - acc: 0.7917\n",
            "Epoch 372/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4552 - acc: 0.7930\n",
            "Epoch 373/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4551 - acc: 0.7917\n",
            "Epoch 374/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4551 - acc: 0.7930\n",
            "Epoch 375/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4550 - acc: 0.7943\n",
            "Epoch 376/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4550 - acc: 0.7930\n",
            "Epoch 377/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4549 - acc: 0.7943\n",
            "Epoch 378/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4548 - acc: 0.7943\n",
            "Epoch 379/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4548 - acc: 0.7943\n",
            "Epoch 380/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4547 - acc: 0.7930\n",
            "Epoch 381/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4546 - acc: 0.7917\n",
            "Epoch 382/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4546 - acc: 0.7930\n",
            "Epoch 383/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4545 - acc: 0.7930\n",
            "Epoch 384/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4545 - acc: 0.7943\n",
            "Epoch 385/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4544 - acc: 0.7930\n",
            "Epoch 386/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4544 - acc: 0.7943\n",
            "Epoch 387/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4543 - acc: 0.7917\n",
            "Epoch 388/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4543 - acc: 0.7930\n",
            "Epoch 389/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4542 - acc: 0.7930\n",
            "Epoch 390/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4541 - acc: 0.7943\n",
            "Epoch 391/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4541 - acc: 0.7917\n",
            "Epoch 392/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4540 - acc: 0.7930\n",
            "Epoch 393/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4539 - acc: 0.7943\n",
            "Epoch 394/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4539 - acc: 0.7943\n",
            "Epoch 395/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4538 - acc: 0.7930\n",
            "Epoch 396/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4538 - acc: 0.7943\n",
            "Epoch 397/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4537 - acc: 0.7930\n",
            "Epoch 398/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4537 - acc: 0.7930\n",
            "Epoch 399/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4536 - acc: 0.7930\n",
            "Epoch 400/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4535 - acc: 0.7943\n",
            "Epoch 401/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4535 - acc: 0.7943\n",
            "Epoch 402/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4534 - acc: 0.7917\n",
            "Epoch 403/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4533 - acc: 0.7943\n",
            "Epoch 404/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4533 - acc: 0.7930\n",
            "Epoch 405/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4533 - acc: 0.7917\n",
            "Epoch 406/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4532 - acc: 0.7943\n",
            "Epoch 407/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4531 - acc: 0.7943\n",
            "Epoch 408/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4531 - acc: 0.7943\n",
            "Epoch 409/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4530 - acc: 0.7930\n",
            "Epoch 410/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4530 - acc: 0.7930\n",
            "Epoch 411/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4529 - acc: 0.7943\n",
            "Epoch 412/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4528 - acc: 0.7956\n",
            "Epoch 413/700\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4527 - acc: 0.7930\n",
            "Epoch 414/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4527 - acc: 0.7943\n",
            "Epoch 415/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4526 - acc: 0.7930\n",
            "Epoch 416/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4526 - acc: 0.7917\n",
            "Epoch 417/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4525 - acc: 0.7943\n",
            "Epoch 418/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4524 - acc: 0.7943\n",
            "Epoch 419/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4524 - acc: 0.7943\n",
            "Epoch 420/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4523 - acc: 0.7956\n",
            "Epoch 421/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4522 - acc: 0.7930\n",
            "Epoch 422/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4522 - acc: 0.7930\n",
            "Epoch 423/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4522 - acc: 0.7943\n",
            "Epoch 424/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4521 - acc: 0.7917\n",
            "Epoch 425/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4520 - acc: 0.7904\n",
            "Epoch 426/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4520 - acc: 0.7917\n",
            "Epoch 427/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4520 - acc: 0.7956\n",
            "Epoch 428/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4518 - acc: 0.7930\n",
            "Epoch 429/700\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.4518 - acc: 0.7943\n",
            "Epoch 430/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4518 - acc: 0.7930\n",
            "Epoch 431/700\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.4517 - acc: 0.7943\n",
            "Epoch 432/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4516 - acc: 0.7917\n",
            "Epoch 433/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4516 - acc: 0.7891\n",
            "Epoch 434/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4515 - acc: 0.7956\n",
            "Epoch 435/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4514 - acc: 0.7956\n",
            "Epoch 436/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4514 - acc: 0.7930\n",
            "Epoch 437/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4513 - acc: 0.7956\n",
            "Epoch 438/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4512 - acc: 0.7943\n",
            "Epoch 439/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4512 - acc: 0.7930\n",
            "Epoch 440/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4511 - acc: 0.7943\n",
            "Epoch 441/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4511 - acc: 0.7904\n",
            "Epoch 442/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4510 - acc: 0.7943\n",
            "Epoch 443/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4509 - acc: 0.7930\n",
            "Epoch 444/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4509 - acc: 0.7956\n",
            "Epoch 445/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4507 - acc: 0.7904\n",
            "Epoch 446/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4508 - acc: 0.7865\n",
            "Epoch 447/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4507 - acc: 0.7904\n",
            "Epoch 448/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4506 - acc: 0.7943\n",
            "Epoch 449/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4506 - acc: 0.7891\n",
            "Epoch 450/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4505 - acc: 0.7943\n",
            "Epoch 451/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4504 - acc: 0.7930\n",
            "Epoch 452/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4503 - acc: 0.7917\n",
            "Epoch 453/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4502 - acc: 0.7930\n",
            "Epoch 454/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4502 - acc: 0.7917\n",
            "Epoch 455/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4501 - acc: 0.7917\n",
            "Epoch 456/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4500 - acc: 0.7917\n",
            "Epoch 457/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4500 - acc: 0.7891\n",
            "Epoch 458/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4500 - acc: 0.7891\n",
            "Epoch 459/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4498 - acc: 0.7904\n",
            "Epoch 460/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4498 - acc: 0.7930\n",
            "Epoch 461/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4497 - acc: 0.7930\n",
            "Epoch 462/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4497 - acc: 0.7917\n",
            "Epoch 463/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4496 - acc: 0.7943\n",
            "Epoch 464/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4496 - acc: 0.7943\n",
            "Epoch 465/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4495 - acc: 0.7878\n",
            "Epoch 466/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4495 - acc: 0.7917\n",
            "Epoch 467/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4494 - acc: 0.7917\n",
            "Epoch 468/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4494 - acc: 0.7904\n",
            "Epoch 469/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4493 - acc: 0.7891\n",
            "Epoch 470/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4492 - acc: 0.7878\n",
            "Epoch 471/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4492 - acc: 0.7891\n",
            "Epoch 472/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4491 - acc: 0.7917\n",
            "Epoch 473/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4491 - acc: 0.7904\n",
            "Epoch 474/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4490 - acc: 0.7917\n",
            "Epoch 475/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4490 - acc: 0.7930\n",
            "Epoch 476/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4489 - acc: 0.7917\n",
            "Epoch 477/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4489 - acc: 0.7878\n",
            "Epoch 478/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4488 - acc: 0.7891\n",
            "Epoch 479/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4488 - acc: 0.7891\n",
            "Epoch 480/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4486 - acc: 0.7904\n",
            "Epoch 481/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4486 - acc: 0.7891\n",
            "Epoch 482/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4485 - acc: 0.7891\n",
            "Epoch 483/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4484 - acc: 0.7878\n",
            "Epoch 484/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4484 - acc: 0.7904\n",
            "Epoch 485/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4484 - acc: 0.7891\n",
            "Epoch 486/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4483 - acc: 0.7904\n",
            "Epoch 487/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4483 - acc: 0.7891\n",
            "Epoch 488/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4482 - acc: 0.7904\n",
            "Epoch 489/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4481 - acc: 0.7917\n",
            "Epoch 490/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4481 - acc: 0.7904\n",
            "Epoch 491/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4480 - acc: 0.7904\n",
            "Epoch 492/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4480 - acc: 0.7878\n",
            "Epoch 493/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4480 - acc: 0.7865\n",
            "Epoch 494/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4478 - acc: 0.7891\n",
            "Epoch 495/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4478 - acc: 0.7878\n",
            "Epoch 496/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4478 - acc: 0.7904\n",
            "Epoch 497/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4476 - acc: 0.7904\n",
            "Epoch 498/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4476 - acc: 0.7878\n",
            "Epoch 499/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4476 - acc: 0.7904\n",
            "Epoch 500/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4475 - acc: 0.7891\n",
            "Epoch 501/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4474 - acc: 0.7865\n",
            "Epoch 502/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4473 - acc: 0.7878\n",
            "Epoch 503/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4473 - acc: 0.7878\n",
            "Epoch 504/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4473 - acc: 0.7878\n",
            "Epoch 505/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4472 - acc: 0.7891\n",
            "Epoch 506/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4471 - acc: 0.7891\n",
            "Epoch 507/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4471 - acc: 0.7878\n",
            "Epoch 508/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4470 - acc: 0.7904\n",
            "Epoch 509/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4469 - acc: 0.7917\n",
            "Epoch 510/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4468 - acc: 0.7917\n",
            "Epoch 511/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4468 - acc: 0.7904\n",
            "Epoch 512/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4467 - acc: 0.7904\n",
            "Epoch 513/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4466 - acc: 0.7891\n",
            "Epoch 514/700\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.4466 - acc: 0.7878\n",
            "Epoch 515/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4466 - acc: 0.7891\n",
            "Epoch 516/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4466 - acc: 0.7878\n",
            "Epoch 517/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4465 - acc: 0.7891\n",
            "Epoch 518/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4464 - acc: 0.7891\n",
            "Epoch 519/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4463 - acc: 0.7904\n",
            "Epoch 520/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4463 - acc: 0.7917\n",
            "Epoch 521/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4463 - acc: 0.7904\n",
            "Epoch 522/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4462 - acc: 0.7904\n",
            "Epoch 523/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4461 - acc: 0.7904\n",
            "Epoch 524/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4460 - acc: 0.7904\n",
            "Epoch 525/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4460 - acc: 0.7891\n",
            "Epoch 526/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4458 - acc: 0.7891\n",
            "Epoch 527/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4458 - acc: 0.7917\n",
            "Epoch 528/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4458 - acc: 0.7904\n",
            "Epoch 529/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4457 - acc: 0.7891\n",
            "Epoch 530/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4456 - acc: 0.7904\n",
            "Epoch 531/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4456 - acc: 0.7904\n",
            "Epoch 532/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4455 - acc: 0.7891\n",
            "Epoch 533/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4455 - acc: 0.7904\n",
            "Epoch 534/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4454 - acc: 0.7904\n",
            "Epoch 535/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4453 - acc: 0.7904\n",
            "Epoch 536/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4452 - acc: 0.7904\n",
            "Epoch 537/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4452 - acc: 0.7904\n",
            "Epoch 538/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4452 - acc: 0.7878\n",
            "Epoch 539/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4451 - acc: 0.7904\n",
            "Epoch 540/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4451 - acc: 0.7904\n",
            "Epoch 541/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4450 - acc: 0.7891\n",
            "Epoch 542/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4450 - acc: 0.7904\n",
            "Epoch 543/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4449 - acc: 0.7917\n",
            "Epoch 544/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4448 - acc: 0.7930\n",
            "Epoch 545/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4448 - acc: 0.7904\n",
            "Epoch 546/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4447 - acc: 0.7917\n",
            "Epoch 547/700\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4446 - acc: 0.7917\n",
            "Epoch 548/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4446 - acc: 0.7930\n",
            "Epoch 549/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4446 - acc: 0.7917\n",
            "Epoch 550/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4446 - acc: 0.7930\n",
            "Epoch 551/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4444 - acc: 0.7917\n",
            "Epoch 552/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4444 - acc: 0.7904\n",
            "Epoch 553/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4444 - acc: 0.7930\n",
            "Epoch 554/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4443 - acc: 0.7917\n",
            "Epoch 555/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4444 - acc: 0.7917\n",
            "Epoch 556/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4442 - acc: 0.7917\n",
            "Epoch 557/700\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 0.4441 - acc: 0.7930\n",
            "Epoch 558/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4441 - acc: 0.7904\n",
            "Epoch 559/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4440 - acc: 0.7943\n",
            "Epoch 560/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4439 - acc: 0.7930\n",
            "Epoch 561/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4439 - acc: 0.7930\n",
            "Epoch 562/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4438 - acc: 0.7930\n",
            "Epoch 563/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4439 - acc: 0.7904\n",
            "Epoch 564/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4437 - acc: 0.7943\n",
            "Epoch 565/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4436 - acc: 0.7930\n",
            "Epoch 566/700\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4437 - acc: 0.7917\n",
            "Epoch 567/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4436 - acc: 0.7943\n",
            "Epoch 568/700\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.4435 - acc: 0.7943\n",
            "Epoch 569/700\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.4435 - acc: 0.7917\n",
            "Epoch 570/700\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4435 - acc: 0.7943\n",
            "Epoch 571/700\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.4433 - acc: 0.7904\n",
            "Epoch 572/700\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.4432 - acc: 0.7930\n",
            "Epoch 573/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4433 - acc: 0.7930\n",
            "Epoch 574/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4431 - acc: 0.7917\n",
            "Epoch 575/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4431 - acc: 0.7930\n",
            "Epoch 576/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4430 - acc: 0.7969\n",
            "Epoch 577/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4430 - acc: 0.7930\n",
            "Epoch 578/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4429 - acc: 0.7943\n",
            "Epoch 579/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4428 - acc: 0.7956\n",
            "Epoch 580/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4428 - acc: 0.7943\n",
            "Epoch 581/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4427 - acc: 0.7956\n",
            "Epoch 582/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4426 - acc: 0.7956\n",
            "Epoch 583/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4425 - acc: 0.7917\n",
            "Epoch 584/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4425 - acc: 0.7969\n",
            "Epoch 585/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4424 - acc: 0.7904\n",
            "Epoch 586/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4423 - acc: 0.7956\n",
            "Epoch 587/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4422 - acc: 0.7956\n",
            "Epoch 588/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4423 - acc: 0.7917\n",
            "Epoch 589/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4422 - acc: 0.7956\n",
            "Epoch 590/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4421 - acc: 0.7930\n",
            "Epoch 591/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4420 - acc: 0.7995\n",
            "Epoch 592/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4419 - acc: 0.7956\n",
            "Epoch 593/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4419 - acc: 0.7917\n",
            "Epoch 594/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4419 - acc: 0.7982\n",
            "Epoch 595/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4418 - acc: 0.7904\n",
            "Epoch 596/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4417 - acc: 0.7982\n",
            "Epoch 597/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4416 - acc: 0.7917\n",
            "Epoch 598/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4416 - acc: 0.7943\n",
            "Epoch 599/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4415 - acc: 0.7878\n",
            "Epoch 600/700\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4415 - acc: 0.7943\n",
            "Epoch 601/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4414 - acc: 0.7904\n",
            "Epoch 602/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4414 - acc: 0.7917\n",
            "Epoch 603/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4414 - acc: 0.7969\n",
            "Epoch 604/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4413 - acc: 0.7917\n",
            "Epoch 605/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4414 - acc: 0.7969\n",
            "Epoch 606/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4412 - acc: 0.7904\n",
            "Epoch 607/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4411 - acc: 0.7956\n",
            "Epoch 608/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4412 - acc: 0.7956\n",
            "Epoch 609/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4411 - acc: 0.7904\n",
            "Epoch 610/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4411 - acc: 0.7969\n",
            "Epoch 611/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4410 - acc: 0.7917\n",
            "Epoch 612/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4408 - acc: 0.7943\n",
            "Epoch 613/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4408 - acc: 0.7930\n",
            "Epoch 614/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4408 - acc: 0.7930\n",
            "Epoch 615/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4407 - acc: 0.7982\n",
            "Epoch 616/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4406 - acc: 0.7956\n",
            "Epoch 617/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4407 - acc: 0.7943\n",
            "Epoch 618/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4405 - acc: 0.7995\n",
            "Epoch 619/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4405 - acc: 0.7917\n",
            "Epoch 620/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4405 - acc: 0.7969\n",
            "Epoch 621/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4403 - acc: 0.7943\n",
            "Epoch 622/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4403 - acc: 0.7982\n",
            "Epoch 623/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4402 - acc: 0.7930\n",
            "Epoch 624/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4402 - acc: 0.7956\n",
            "Epoch 625/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4401 - acc: 0.7969\n",
            "Epoch 626/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4400 - acc: 0.7943\n",
            "Epoch 627/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4401 - acc: 0.7995\n",
            "Epoch 628/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4399 - acc: 0.7943\n",
            "Epoch 629/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4398 - acc: 0.7956\n",
            "Epoch 630/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4398 - acc: 0.7943\n",
            "Epoch 631/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4397 - acc: 0.7969\n",
            "Epoch 632/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4396 - acc: 0.7969\n",
            "Epoch 633/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4396 - acc: 0.7956\n",
            "Epoch 634/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4396 - acc: 0.7969\n",
            "Epoch 635/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4394 - acc: 0.7956\n",
            "Epoch 636/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4394 - acc: 0.7956\n",
            "Epoch 637/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4395 - acc: 0.7982\n",
            "Epoch 638/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4396 - acc: 0.7904\n",
            "Epoch 639/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4397 - acc: 0.7930\n",
            "Epoch 640/700\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4394 - acc: 0.7917\n",
            "Epoch 641/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4392 - acc: 0.7995\n",
            "Epoch 642/700\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4391 - acc: 0.7969\n",
            "Epoch 643/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4390 - acc: 0.7956\n",
            "Epoch 644/700\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4390 - acc: 0.7943\n",
            "Epoch 645/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4389 - acc: 0.7943\n",
            "Epoch 646/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4389 - acc: 0.7982\n",
            "Epoch 647/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4389 - acc: 0.7943\n",
            "Epoch 648/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4389 - acc: 0.7982\n",
            "Epoch 649/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4389 - acc: 0.7956\n",
            "Epoch 650/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4387 - acc: 0.7995\n",
            "Epoch 651/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4386 - acc: 0.7956\n",
            "Epoch 652/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4385 - acc: 0.7956\n",
            "Epoch 653/700\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4386 - acc: 0.7982\n",
            "Epoch 654/700\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4387 - acc: 0.7930\n",
            "Epoch 655/700\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.4386 - acc: 0.7930\n",
            "Epoch 656/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4385 - acc: 0.7904\n",
            "Epoch 657/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4383 - acc: 0.7995\n",
            "Epoch 658/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4382 - acc: 0.7969\n",
            "Epoch 659/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4382 - acc: 0.7969\n",
            "Epoch 660/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4381 - acc: 0.7995\n",
            "Epoch 661/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4381 - acc: 0.7969\n",
            "Epoch 662/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4381 - acc: 0.7969\n",
            "Epoch 663/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4380 - acc: 0.7969\n",
            "Epoch 664/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4380 - acc: 0.7930\n",
            "Epoch 665/700\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4380 - acc: 0.7956\n",
            "Epoch 666/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4380 - acc: 0.7943\n",
            "Epoch 667/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4379 - acc: 0.7969\n",
            "Epoch 668/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4377 - acc: 0.7969\n",
            "Epoch 669/700\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.4377 - acc: 0.7982\n",
            "Epoch 670/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4377 - acc: 0.7982\n",
            "Epoch 671/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4377 - acc: 0.7956\n",
            "Epoch 672/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4377 - acc: 0.7969\n",
            "Epoch 673/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4375 - acc: 0.7956\n",
            "Epoch 674/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4374 - acc: 0.7995\n",
            "Epoch 675/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4374 - acc: 0.7995\n",
            "Epoch 676/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4374 - acc: 0.7969\n",
            "Epoch 677/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4375 - acc: 0.7943\n",
            "Epoch 678/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4376 - acc: 0.7930\n",
            "Epoch 679/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4374 - acc: 0.7943\n",
            "Epoch 680/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4372 - acc: 0.7930\n",
            "Epoch 681/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4370 - acc: 0.7995\n",
            "Epoch 682/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4370 - acc: 0.7969\n",
            "Epoch 683/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4369 - acc: 0.7956\n",
            "Epoch 684/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4369 - acc: 0.7969\n",
            "Epoch 685/700\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4368 - acc: 0.7982\n",
            "Epoch 686/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4367 - acc: 0.7982\n",
            "Epoch 687/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4368 - acc: 0.7969\n",
            "Epoch 688/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4367 - acc: 0.7982\n",
            "Epoch 689/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4366 - acc: 0.7969\n",
            "Epoch 690/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4366 - acc: 0.7956\n",
            "Epoch 691/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4366 - acc: 0.7943\n",
            "Epoch 692/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4366 - acc: 0.7943\n",
            "Epoch 693/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4368 - acc: 0.7943\n",
            "Epoch 694/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4368 - acc: 0.7930\n",
            "Epoch 695/700\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4367 - acc: 0.7930\n",
            "Epoch 696/700\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4365 - acc: 0.7995\n",
            "Epoch 697/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4364 - acc: 0.7982\n",
            "Epoch 698/700\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4364 - acc: 0.7930\n",
            "Epoch 699/700\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4364 - acc: 0.7943\n",
            "Epoch 700/700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4364 - acc: 0.7956\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9869495550>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(8,),name='input')\n",
        "dense1 = tf.keras.layers.Dense(units=12,activation='relu',name='dense1')(inputs)\n",
        "dense2 = tf.keras.layers.Dense(units=8,activation='relu',name='dense2')(dense1)\n",
        "outputs = tf.keras.layers.Dense(units=1,activation='sigmoid',name='outputs')(dense2)\n",
        "\n",
        "model5 = tf.keras.Model(inputs=inputs,outputs=outputs)\n",
        "model5.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=['acc'])\n",
        "model5.fit(x,y,batch_size=100,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYH5JkafdKyS",
        "outputId": "1f1c43f0-9ade-4861-c375-54d8f8083e7c"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 1s 2ms/step - loss: 34.9332 - acc: 0.6510\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 30.9787 - acc: 0.6510\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 27.3434 - acc: 0.6510\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 23.8428 - acc: 0.6510\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 20.5280 - acc: 0.6497\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 17.0788 - acc: 0.6458\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 13.4600 - acc: 0.6302\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 9.9294 - acc: 0.5911\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 7.3499 - acc: 0.5365\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 5.7333 - acc: 0.4688\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 4.5332 - acc: 0.4766\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.5920 - acc: 0.5065\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 3.0124 - acc: 0.4961\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 2.5414 - acc: 0.4831\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 2.2314 - acc: 0.5013\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.9559 - acc: 0.5013\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.7241 - acc: 0.5326\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.5337 - acc: 0.5378\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3925 - acc: 0.5443\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.3004 - acc: 0.5430\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.2304 - acc: 0.5547\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1592 - acc: 0.5612\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.1102 - acc: 0.5651\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0622 - acc: 0.5859\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 1.0142 - acc: 0.5833\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9803 - acc: 0.5859\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9522 - acc: 0.6185\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9276 - acc: 0.6172\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.9119 - acc: 0.6120\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8966 - acc: 0.6159\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8799 - acc: 0.6211\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8646 - acc: 0.6185\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8542 - acc: 0.6185\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8459 - acc: 0.6185\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8385 - acc: 0.6211\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8312 - acc: 0.6211\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8226 - acc: 0.6185\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8139 - acc: 0.6315\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8173 - acc: 0.6237\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.8050 - acc: 0.6380\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7995 - acc: 0.6328\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7905 - acc: 0.6367\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7889 - acc: 0.6445\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7921 - acc: 0.6432\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7798 - acc: 0.6328\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7747 - acc: 0.6471\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.7685 - acc: 0.6380\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7616 - acc: 0.6393\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7618 - acc: 0.6419\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7556 - acc: 0.6393\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7514 - acc: 0.6393\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7479 - acc: 0.6458\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7433 - acc: 0.6510\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7415 - acc: 0.6589\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7405 - acc: 0.6458\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7316 - acc: 0.6523\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7281 - acc: 0.6497\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7264 - acc: 0.6576\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7261 - acc: 0.6602\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.7193 - acc: 0.6628\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7258 - acc: 0.6615\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7160 - acc: 0.6523\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7053 - acc: 0.6576\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7045 - acc: 0.6654\n",
            "Epoch 65/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.7016 - acc: 0.6628\n",
            "Epoch 66/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6998 - acc: 0.6615\n",
            "Epoch 67/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6988 - acc: 0.6680\n",
            "Epoch 68/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6932 - acc: 0.6719\n",
            "Epoch 69/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6985 - acc: 0.6576\n",
            "Epoch 70/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6962 - acc: 0.6615\n",
            "Epoch 71/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6887 - acc: 0.6680\n",
            "Epoch 72/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6893 - acc: 0.6771\n",
            "Epoch 73/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6831 - acc: 0.6641\n",
            "Epoch 74/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6960 - acc: 0.6576\n",
            "Epoch 75/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6904 - acc: 0.6654\n",
            "Epoch 76/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6820 - acc: 0.6732\n",
            "Epoch 77/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6827 - acc: 0.6589\n",
            "Epoch 78/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6732 - acc: 0.6745\n",
            "Epoch 79/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6756 - acc: 0.6875\n",
            "Epoch 80/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6722 - acc: 0.6706\n",
            "Epoch 81/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6768 - acc: 0.6641\n",
            "Epoch 82/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6725 - acc: 0.6771\n",
            "Epoch 83/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6678 - acc: 0.6797\n",
            "Epoch 84/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6680 - acc: 0.6706\n",
            "Epoch 85/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6677 - acc: 0.6628\n",
            "Epoch 86/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6632 - acc: 0.6784\n",
            "Epoch 87/100\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.6716 - acc: 0.6576\n",
            "Epoch 88/100\n",
            "8/8 [==============================] - 0s 2ms/step - loss: 0.6647 - acc: 0.6810\n",
            "Epoch 89/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6564 - acc: 0.6758\n",
            "Epoch 90/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6476 - acc: 0.6810\n",
            "Epoch 91/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6613 - acc: 0.6797\n",
            "Epoch 92/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6519 - acc: 0.6745\n",
            "Epoch 93/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6538 - acc: 0.6667\n",
            "Epoch 94/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6487 - acc: 0.6797\n",
            "Epoch 95/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6520 - acc: 0.6745\n",
            "Epoch 96/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6467 - acc: 0.6849\n",
            "Epoch 97/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6439 - acc: 0.6862\n",
            "Epoch 98/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6421 - acc: 0.6849\n",
            "Epoch 99/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6388 - acc: 0.6810\n",
            "Epoch 100/100\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.6420 - acc: 0.6836\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9868f56650>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "class indian(tf.keras.Model):\n",
        "  def __init__(self,hidden1,hidden2,outputs):\n",
        "    super(indian,self).__init__()\n",
        "    self.dense1 = tf.keras.layers.Dense(units=hidden1,activation=\"relu\")\n",
        "    self.dense2 = tf.keras.layers.Dense(units=hidden2,activation=\"relu\")\n",
        "    self.outputs = tf.keras.layers.Dense(units=outputs,activation=\"sigmoid\")\n",
        "\n",
        "  def call(self,inputs):\n",
        "    self.dense1(inputs)\n",
        "    self.dense2(self.dense1)\n",
        "\n",
        "    return self.outputs(self.dense2)\n",
        "\n",
        "model_indian = indian(12,8,1)\n",
        "model_indian.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=['acc'])\n",
        "model_indian.fit(x,y,batch_size=100,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 922
        },
        "id": "OpGaTSZlhxCm",
        "outputId": "54a9ff30-ebf4-4113-9ca2-6c9a895d78f7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-1ff48e20e7af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel_indian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel_indian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel_indian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filesyl6t090.py\u001b[0m in \u001b[0;36mtf__call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filesyl6t090.py\", line 11, in tf__call\n        ag__.converted_call(ag__.ld(self).dense2, (ag__.ld(self).dense1,), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"indian_10\" (type indian).\n    \n    in user code:\n    \n        File \"<ipython-input-73-1d1ad9fd4b55>\", line 11, in call  *\n            self.dense2(self.dense1)\n        File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py\", line 197, in assert_input_compatibility\n            raise TypeError(f'Inputs to a layer should be tensors. Got: {x}')\n    \n        TypeError: Inputs to a layer should be tensors. Got: <keras.layers.core.dense.Dense object at 0x7f9862c0afd0>\n    \n    \n    Call arguments received by layer \"indian_10\" (type indian):\n      • inputs=tf.Tensor(shape=(None, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=\"{epochs:2d}_{val_loss:4f\",moitor=\"val_loss\",verbose=1,save_best_only=True,save_weigths_only=True)\n",
        "early_sstopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=10)\n",
        "\n"
      ],
      "metadata": {
        "id": "iE19nMhejpKx"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class indian(tf.keras.Model):\n",
        "  def __init__(self,hidden1,hidden2,outputs):\n",
        "    super(indian, self).__init__(name=\"indian\")\n",
        "    self.dense1 = tf.keras.layers.Dense(units=hidden1,activation=\"relu\")\n",
        "    self.dense2 = tf.keras.layers.Dense(units=hidden2,activation=\"relu\")\n",
        "    self.outputs = tf.keras.layers.Dense(units=outputs,activation=\"sigmoid\")\n",
        "\n",
        "  def call(self,inputs):\n",
        "    self.dens1(inputs)\n",
        "    self.dens2(self.dens1)\n",
        "\n",
        "    return self.outputs(self.dense2)\n",
        "\n",
        "model_indian = indian(12,8,1)\n",
        "model_indian.summary()\n",
        "model_indian.compile(optimizer=\"Adam\",loss=\"binary_crossentropy\",metrics=['acc'])\n",
        "model_indian.fit(x,y,batch_size=100,epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "5wydZQjso_Qo",
        "outputId": "8de81d22-f528-4595-a95b-41d0b09ba97e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-9167b312f9d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel_indian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel_indian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmodel_indian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Adam\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel_indian\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn, expand_nested, show_trainable)\u001b[0m\n\u001b[1;32m   2868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2869\u001b[0m       raise ValueError(\n\u001b[0;32m-> 2870\u001b[0;31m           \u001b[0;34m'This model has not yet been built. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2871\u001b[0m           \u001b[0;34m'Build the model first by calling `build()` or by calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2872\u001b[0m           'the model on a batch of data.')\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or by calling the model on a batch of data."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WvO0wuxlpAEV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}